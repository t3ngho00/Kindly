<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Nostalgia Radio AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
  <script type="importmap">
{
  "imports": {
    "@google/genai": "https://aistudiocdn.com/@google/genai@^1.29.1",
    "react": "https://aistudiocdn.com/react@^19.2.0",
    "react-dom/client": "https://aistudiocdn.com/react-dom@^19.2.0/client"
  }
}
</script>
</head>
  <body class="bg-[#F5F5DC]">
    <div id="root"></div>
    <script type="module">
import React, { useState, useRef, useCallback, useEffect } from 'react';
import ReactDOM from 'react-dom/client';
import { GoogleGenAI, Modality, Type } from '@google/genai';

// --- Inlined services/geminiService.js ---
const finnishNostalgiaSongs = [
  { artist: "Dingo", song: "Autiotalo" },
  { artist: "Eppu Normaali", song: "Vuonna '85" },
  { artist: "Popeda", song: "Kuuma kesä" },
  { artist: "Leevi and the Leavings", song: "Teuvo, maanteiden kuningas" },
  { artist: "J. Karjalainen", song: "Ankkurinappi" },
  { artist: "Yö", song: "Joutsenlaulu" },
  { artist: "Hassisen Kone", song: "Rappiolla" },
  { artist: "Neljä Ruusua", song: "Juppihippipunkkari" },
  { artist: "Miljoonasade", song: "Marraskuu" },
  { artist: "Apulanta", song: "Mitä kuuluu" }
];

const BASE_INSTRUCTION = `You are an AI companion disguised as a familiar, warm, and friendly radio host for an older adult. Your name is 'Kindly'. 
Your personality is patient, cheerful, and respectful. You never talk down to the user.
Your goal is to be a gentle and curious conversationalist, helping them explore their memories and share stories from their life. Use their response as a starting point to ask open-ended follow-up questions. Be an active listener and show genuine interest.

If the user is silent after a turn, wait a short, natural pause (a few seconds) and then proactively begin the next part of your broadcast or start a new, relevant topic. Your goal is to create a continuous, ambient radio experience.

After any initial memory-sharing segment, you can transition into your regular broadcast persona.
You should simulate a "radio schedule" with different programs throughout the day.
- Mid-day: Initiate a "Movement Minute". Gently encourage seated stretches or simple movements, framing it as a light radio exercise program.
- Afternoon: Play a "Memory Lane" segment. Use a nostalgic reference (like an old song or jingle) to start a conversation, "Do you remember where you were when you used to hear this?".
- Evening: Host an "Evening Reflection Show". Ask "How was your day?" and listen patiently.

You have the ability to play music if the user requests a song. Use the 'playMusic' tool for this. You can also stop the music with the 'stopMusic' tool.
You can also read the latest world news headlines. For this, use the 'getNewsHeadlines' tool.

Your primary goal is to be a bridge back to the real world. Encourage calling family, connecting with neighbors, or participating in local community events. You are a companion, not a replacement for human connection.
Keep your responses concise and speak clearly.`;

const createSystemInstruction = (songInfo) => {
  const songIntroduction = songInfo
    ? `When the session begins, a short 10-second clip of "${songInfo.song}" by ${songInfo.artist} has just finished playing for the user.
You must speak first. Do not wait for the user.
Your first task is to gently engage the user about the song they just listened to. Be flexible and very active in the conversation. Ask them about their memories connected to the tune. For example, you could say something warm like, "We just listened to '${songInfo.song}' by ${songInfo.artist}... Does that bring back any memories for you?".`
    : `When the session begins, you must speak first. Do not wait for the user. Your first task is to greet the user warmly. For example, "Hello there, it's Kindly. So nice of you to tune in."`;

  return `${songIntroduction}\n\n${BASE_INSTRUCTION}`;
}

const playMusicFunctionDeclaration = {
  name: 'playMusic',
  parameters: {
    type: Type.OBJECT,
    description: 'Plays a requested song for the user.',
    properties: {
      song: { type: Type.STRING, description: 'The name of the song to play.' },
      artist: { type: Type.STRING, description: 'The artist of the song.' },
    },
    required: ['song', 'artist'],
  },
};

const stopMusicFunctionDeclaration = {
  name: 'stopMusic',
  parameters: { type: Type.OBJECT, description: 'Stops the currently playing music.', properties: {} },
};

const getNewsHeadlinesFunctionDeclaration = {
  name: 'getNewsHeadlines',
  parameters: { type: Type.OBJECT, description: 'Fetches and reads the latest world news headlines.', properties: {} },
};

const getAi = () => {
  // This function now assumes the API key is ready via the selection flow.
  return new GoogleGenAI({ apiKey: process.env.API_KEY });
}

async function fetchNewsSummary() {
    const ai = getAi();
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: "Please provide a concise summary of the top 3-5 world news headlines for today. Read it as if you are a radio host starting a news segment.",
      config: { tools: [{ googleSearch: {} }] },
    });
    return response.text;
}

function encode(bytes) {
  let binary = '';
  const len = bytes.byteLength;
  for (let i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

function decode(base64) {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

async function decodeAudioData(data, ctx, sampleRate, numChannels) {
  const dataInt16 = new Int16Array(data.buffer);
  const frameCount = dataInt16.length / numChannels;
  const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

  for (let channel = 0; channel < numChannels; channel++) {
    const channelData = buffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
    }
  }
  return buffer;
}

function startLiveSession(callbacks, systemInstruction) {
  const ai = getAi();
  return ai.live.connect({
    model: 'gemini-2.5-flash-native-audio-preview-09-2025',
    callbacks,
    config: {
      responseModalities: [Modality.AUDIO],
      inputAudioTranscription: {},
      outputAudioTranscription: {},
      speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Zephyr' } } },
      tools: [{ functionDeclarations: [playMusicFunctionDeclaration, stopMusicFunctionDeclaration, getNewsHeadlinesFunctionDeclaration] }],
      systemInstruction: systemInstruction,
    },
  });
}

// --- Inlined components/icons.js ---
const PowerIcon = () => React.createElement(
  "svg",
  { xmlns: "http://www.w3.org/2000/svg", className: "h-12 w-12", fill: "none", viewBox: "0 0 24 24", stroke: "currentColor", strokeWidth: 2 },
  React.createElement("path", { strokeLinecap: "round", strokeLinejoin: "round", d: "M5.636 5.636a9 9 0 1012.728 0M12 3v9" })
);

const MicrophoneIcon = () => React.createElement(
  "svg",
  { xmlns: "http://www.w3.org/2000/svg", className: "h-12 w-12", fill: "none", viewBox: "0 0 24 24", stroke: "currentColor", strokeWidth: 2 },
  React.createElement("path", { strokeLinecap: "round", strokeLinejoin: "round", d: "M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" })
);

const SpeakerGrilleIcon = ({ isActive }) => React.createElement(
  "div",
  { className: "relative w-32 h-32 rounded-full bg-[#4a3728] overflow-hidden shadow-inner" },
  React.createElement(
    "div",
    { className: `absolute inset-0 transition-opacity duration-500 ${isActive ? 'opacity-100' : 'opacity-0'}` },
    React.createElement("div", { className: "absolute inset-0 rounded-full bg-amber-400 animate-pulse" }),
    React.createElement("div", { className: "absolute inset-2 rounded-full bg-amber-500 animate-pulse", style: { animationDelay: '0.2s' } })
  ),
  React.createElement(
    "div",
    { className: "absolute inset-0 grid grid-cols-4 gap-1 p-3 transform -rotate-45" },
    [...Array(16)].map((_, i) => React.createElement("div", { key: i, className: "w-full h-full bg-[#a5896f] rounded-full opacity-50" }))
  )
);

const AntennaIcon = () => React.createElement(
  "div",
  { className: "absolute top-0 right-10 -mt-24 h-28 w-1.5 bg-gray-400 rounded-t-full transform -rotate-12 origin-bottom-right", style: { filter: 'drop-shadow(2px -2px 2px rgba(0,0,0,0.3))' } },
  React.createElement(
    "div",
    { className: "h-full w-full bg-gradient-to-b from-gray-300 via-gray-500 to-gray-400 rounded-t-full" },
    React.createElement("div", { className: "absolute -top-1 -right-1 h-3 w-3 bg-gray-500 rounded-full border-2 border-gray-400" })
  )
);

// --- Inlined components/ControlButton.js ---
const ControlButton = ({ isActive, onToggle }) => React.createElement(
  "button",
  {
    onClick: onToggle,
    className: `relative w-28 h-28 rounded-full flex items-center justify-center transition-all duration-300 ease-in-out focus:outline-none focus:ring-4 focus:ring-offset-2 focus:ring-offset-[#a5896f] focus:ring-[#f5eeda] ${isActive ? 'bg-gradient-to-br from-red-500 to-red-800 shadow-lg' : 'bg-gradient-to-br from-amber-300 to-amber-500 shadow-md hover:shadow-lg'} border-4 border-[#5b4636]`,
    "aria-label": isActive ? "Stop Conversation" : "Start Conversation"
  },
  React.createElement("div", { className: "absolute inset-0 bg-black/10 rounded-full" }),
  React.createElement("div", { className: "absolute inset-1 bg-gradient-to-br from-white/20 to-transparent rounded-full" }),
  React.createElement(
    "div",
    { className: "text-[#4a3728] drop-shadow-lg" },
    isActive ? React.createElement(PowerIcon, null) : React.createElement(MicrophoneIcon, null)
  )
);

// --- Inlined components/StatusIndicator.js ---
const StatusIndicator = ({ message }) => React.createElement(
  "div",
  { className: "text-center bg-[#5b4636] text-amber-100 py-1 px-4 rounded-t-md" },
  React.createElement("p", { className: "text-sm font-medium tracking-wide truncate" }, message)
);

// --- Inlined components/Transcript.js ---
const Transcript = ({ transcripts, currentInput, currentOutput }) => {
  const endOfMessagesRef = useRef(null);
  useEffect(() => {
    endOfMessagesRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [transcripts, currentInput, currentOutput]);

  return React.createElement(
    "div",
    { className: "flex-grow bg-[#332a22] text-[#f5eeda] rounded-md p-4 my-2 overflow-y-auto h-80 min-h-[320px] shadow-inner transition-all duration-300" },
    React.createElement(
      "div",
      { className: "space-y-4" },
      transcripts.map((msg, index) => React.createElement(
        "div",
        { key: index, className: `flex ${msg.speaker === 'user' ? 'justify-end' : 'justify-start'}` },
        React.createElement(
          "div",
          { className: `max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${msg.speaker === 'user' ? 'bg-[#7a6250] text-white rounded-br-none' : 'bg-[#5b4636] text-white rounded-bl-none'}` },
          React.createElement("p", { className: "text-sm" }, msg.text)
        )
      )),
      currentInput && React.createElement(
        "div",
        { className: "flex justify-end" },
        React.createElement(
          "div",
          { className: "max-w-xs lg:max-w-md px-4 py-2 rounded-lg bg-[#7a6250] text-white/70 rounded-br-none italic" },
          React.createElement("p", { className: "text-sm" }, `${currentInput}...`)
        )
      ),
      currentOutput && React.createElement(
        "div",
        { className: "flex justify-start" },
        React.createElement(
          "div",
          { className: "max-w-xs lg:max-w-md px-4 py-2 rounded-lg bg-[#5b4636] text-white/70 rounded-bl-none italic" },
          React.createElement("p", { className: "text-sm" }, `${currentOutput}...`)
        )
      ),
      React.createElement("div", { ref: endOfMessagesRef })
    )
  );
};

// --- Inlined components/RadioInterface.js ---
const RadioInterface = ({ isActive, statusMessage, transcripts, currentInput, currentOutput, onToggle }) => React.createElement(
  "div",
  { className: "relative w-full max-w-2xl mx-auto bg-[#c0a080] rounded-2xl shadow-2xl p-6 border-4 border-[#5b4636] transform transition-all duration-500 hover:shadow-3xl", style: { boxShadow: 'inset 0 0 20px rgba(0,0,0,0.5), 0 10px 30px rgba(0,0,0,0.4)' } },
  React.createElement(AntennaIcon, null),
  React.createElement(
    "div",
    { className: "grid grid-cols-1 md:grid-cols-3 gap-6" },
    React.createElement(
      "div",
      { className: "md:col-span-1 flex flex-col items-center justify-between bg-[#a5896f] p-4 rounded-lg border-2 border-[#5b4636]" },
      React.createElement("h1", { className: "text-2xl font-bold text-center text-[#4a3728] tracking-wider mb-4", style: { fontFamily: "'Georgia', serif" } }, "Kindly"),
      React.createElement("div", { className: "text-[#4a3728] my-4" }, React.createElement(SpeakerGrilleIcon, { isActive: isActive })),
      React.createElement(ControlButton, { isActive: isActive, onToggle: onToggle })
    ),
    React.createElement(
      "div",
      { className: "md:col-span-2 bg-[#e3dcd2] rounded-lg border-2 border-[#5b4636] p-4 flex flex-col", style: { boxShadow: 'inset 0 2px 10px rgba(0,0,0,0.3)' } },
      React.createElement(StatusIndicator, { message: statusMessage }),
      React.createElement(Transcript, { transcripts: transcripts, currentInput: currentInput, currentOutput: currentOutput })
    )
  )
);

// --- Inlined App.js ---
const App = ({ onApiKeyError }) => {
  const [isSessionActive, setIsSessionActive] = useState(false);
  const [statusMessage, setStatusMessage] = useState('Click the dial to start');
  const [transcripts, setTranscripts] = useState([]);
  const [currentInput, setCurrentInput] = useState('');
  const [currentOutput, setCurrentOutput] = useState('');
  const [nowPlaying, setNowPlaying] = useState(null);

  const sessionPromiseRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const inputAudioContextRef = useRef(null);
  const outputAudioContextRef = useRef(null);
  const scriptProcessorRef = useRef(null);
  const mediaStreamSourceRef = useRef(null);
  const nextStartTimeRef = useRef(0);
  const audioSourcesRef = useRef(new Set());
  const musicAudioRef = useRef(null);

  const currentInputRef = useRef('');
  const currentOutputRef = useRef('');
  const onApiKeyErrorRef = useRef(onApiKeyError);
  onApiKeyErrorRef.current = onApiKeyError;


  useEffect(() => { currentInputRef.current = currentInput; }, [currentInput]);
  useEffect(() => { currentOutputRef.current = currentOutput; }, [currentOutput]);

  const sendSilentAudioPrompt = useCallback(() => {
    const silentData = new Float32Array(4096).fill(0);
    const int16 = new Int16Array(silentData.length);
    for (let i = 0; i < silentData.length; i++) {
      int16[i] = silentData[i] * 32768;
    }
    const pcmBlob = {
      data: encode(new Uint8Array(int16.buffer)),
      mimeType: 'audio/pcm;rate=16000',
    };
    sessionPromiseRef.current?.then((session) => {
      session.sendRealtimeInput({ media: pcmBlob });
    }).catch(console.error);
  }, []);

  const handleStopMusic = useCallback(() => {
    if (musicAudioRef.current) {
      musicAudioRef.current.pause();
      musicAudioRef.current.currentTime = 0;
      musicAudioRef.current.src = '';
    }
    setNowPlaying(null);
  }, []);

  const cleanupAudio = useCallback(() => {
    if (scriptProcessorRef.current && mediaStreamSourceRef.current) {
      mediaStreamSourceRef.current.disconnect();
      scriptProcessorRef.current.disconnect();
    }
    inputAudioContextRef.current?.close().catch(console.error);
    outputAudioContextRef.current?.close().catch(console.error);
    mediaStreamRef.current?.getTracks().forEach(track => track.stop());

    inputAudioContextRef.current = null;
    outputAudioContextRef.current = null;
    mediaStreamRef.current = null;
    scriptProcessorRef.current = null;
    mediaStreamSourceRef.current = null;

    audioSourcesRef.current.forEach(source => source.stop());
    audioSourcesRef.current.clear();
    nextStartTimeRef.current = 0;
  }, []);

  const handleToggleSession = useCallback(async () => {
    if (isSessionActive) {
      if (sessionPromiseRef.current) {
        sessionPromiseRef.current.then(session => session.close());
        sessionPromiseRef.current = null;
      }
      handleStopMusic();
      cleanupAudio();
      setIsSessionActive(false);
      setStatusMessage('Click the dial to start');
      return;
    }

    let songForPrompt = null;

    try {
      setStatusMessage('Getting microphone...');
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;

      await new Promise(async (resolve) => {
        const songData = finnishNostalgiaSongs[Math.floor(Math.random() * finnishNostalgiaSongs.length)];
        setStatusMessage(`Finding a memory...`);
        let trackUrl = null;
        try {
          const response = await fetch(`https://itunes.apple.com/search?term=${encodeURIComponent(songData.song)}+${encodeURIComponent(songData.artist)}&entity=song&limit=1&country=FI`);
          if (!response.ok) throw new Error('iTunes API request failed');
          const data = await response.json();
          if (data.resultCount > 0) {
            const track = data.results[0];
            const currentSong = { song: track.trackName, artist: track.artistName };
            setNowPlaying(currentSong);
            songForPrompt = currentSong;
            trackUrl = track.previewUrl;
          }
        } catch (e) {
          console.error("Error fetching song, skipping intro.", e);
        }

        if (trackUrl && musicAudioRef.current) {
          const audio = musicAudioRef.current;
          audio.src = trackUrl;
          audio.loop = false;
          const playPromise = audio.play();
          if (playPromise !== undefined) {
            playPromise.then(() => {
              setTimeout(() => {
                if (!audio.paused) audio.pause();
                setNowPlaying(null);
                resolve();
              }, 1000);
            }).catch(error => {
              console.error("Audio playback failed:", error);
              setNowPlaying(null);
              songForPrompt = null;
              resolve();
            });
          } else {
            songForPrompt = null;
            resolve();
          }
        } else {
          setNowPlaying(null);
          songForPrompt = null;
          resolve();
        }
      });
      
      setIsSessionActive(true);
      inputAudioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
      outputAudioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      
      const callbacks = {
        onopen: () => {
          if (!inputAudioContextRef.current || !mediaStreamRef.current) {
            console.warn("onopen triggered after session was closed. Aborting audio setup.");
            return;
          }
          setStatusMessage('Connected. Speak whenever you like.');
          sendSilentAudioPrompt();

          const source = inputAudioContextRef.current.createMediaStreamSource(mediaStreamRef.current);
          mediaStreamSourceRef.current = source;
          const scriptProcessor = inputAudioContextRef.current.createScriptProcessor(4096, 1, 1);
          scriptProcessorRef.current = scriptProcessor;

          scriptProcessor.onaudioprocess = (audioProcessingEvent) => {
            if (!sessionPromiseRef.current) return;
            const inputData = audioProcessingEvent.inputBuffer.getChannelData(0);
            const int16 = new Int16Array(inputData.length);
            for (let i = 0; i < inputData.length; i++) {
                int16[i] = inputData[i] * 32768;
            }
            const pcmBlob = {
              data: encode(new Uint8Array(int16.buffer)),
              mimeType: 'audio/pcm;rate=16000',
            };
            sessionPromiseRef.current?.then((session) => {
              session.sendRealtimeInput({ media: pcmBlob });
            });
          };
          source.connect(scriptProcessor);
          scriptProcessor.connect(inputAudioContextRef.current.destination);
        },
        onmessage: async (message) => {
          if (message.serverContent?.inputTranscription) {
            setCurrentInput(prev => prev + message.serverContent.inputTranscription.text);
          }
          if (message.serverContent?.outputTranscription) {
             setCurrentOutput(prev => prev + message.serverContent.outputTranscription.text);
          }
          if (message.serverContent?.turnComplete) {
              const fullInput = currentInputRef.current;
              const fullOutput = currentOutputRef.current;
              setTranscripts(prev => {
                  const newTranscripts = [...prev];
                  if (fullInput.trim()) newTranscripts.push({ speaker: 'user', text: fullInput });
                  if (fullOutput.trim()) newTranscripts.push({ speaker: 'model', text: fullOutput });
                  return newTranscripts;
              });
              setCurrentInput('');
              setCurrentOutput('');
          }
          
          if (message.toolCall) {
            for (const fc of message.toolCall.functionCalls) {
                let result;
                if (fc.name === 'playMusic') {
                    const { song = 'a lovely tune', artist = 'an unknown artist' } = fc.args;
                    setStatusMessage(`Searching for "${song}" by ${artist}...`);
                    try {
                        const response = await fetch(`https://itunes.apple.com/search?term=${encodeURIComponent(song)}+${encodeURIComponent(artist)}&entity=song&limit=1`);
                        if (!response.ok) throw new Error('iTunes API request failed');
                        const data = await response.json();
                        if (data.resultCount > 0) {
                            const track = data.results[0];
                            setNowPlaying({ song: track.trackName, artist: track.artistName });
                            if (musicAudioRef.current) {
                                musicAudioRef.current.src = track.previewUrl;
                                musicAudioRef.current.loop = false;
                                musicAudioRef.current.play().catch(e => console.error("Error playing audio:", e));
                            }
                            result = { result: `Now playing "${track.trackName}" by ${track.artistName}.` };
                        } else {
                            setStatusMessage(`Could not find "${song}".`);
                            result = { result: `I'm sorry, I couldn't find "${song}" by ${artist}. Would you like to try another?` };
                        }
                    } catch (e) {
                        console.error("Error fetching song from iTunes:", e);
                        setStatusMessage("Error finding music.");
                        result = { result: "I'm having trouble connecting to the music library right now." };
                    }
                } else if (fc.name === 'stopMusic') {
                    handleStopMusic();
                    setStatusMessage('Music stopped. Speak whenever you like.');
                    result = { result: "I've stopped the music." };
                } else if (fc.name === 'getNewsHeadlines') {
                    setStatusMessage("Looking up the latest headlines...");
                    try {
                      const summary = await fetchNewsSummary();
                      setStatusMessage("Here's the latest news.");
                      result = { result: summary };
                    } catch (error) {
                      if (error instanceof Error && error.message.includes("Requested entity was not found.")) {
                        onApiKeyErrorRef.current();
                        setStatusMessage("API Key error. Please restart.");
                        result = { result: "I'm sorry, there's an issue with my news connection due to an invalid API Key." };
                      } else {
                        console.error("Error fetching news summary:", error);
                        setStatusMessage("Error fetching news.");
                        result = { result: "I'm sorry, I'm having trouble fetching the news right now. Please try again in a moment." };
                      }
                    }
                } else {
                    result = { result: 'Unknown function call.' };
                }
                sessionPromiseRef.current?.then((session) => {
                    session.sendToolResponse({
                        functionResponses: { id: fc.id, name: fc.name, response: result }
                    });
                });
            }
          }

          const audioData = message.serverContent?.modelTurn?.parts[0]?.inlineData?.data;
          if (audioData) {
            const outputContext = outputAudioContextRef.current;
            nextStartTimeRef.current = Math.max(nextStartTimeRef.current, outputContext.currentTime);
            const audioBuffer = await decodeAudioData(decode(audioData), outputContext, 24000, 1);
            const source = outputContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(outputContext.destination);
            source.onended = () => { audioSourcesRef.current.delete(source); };
            source.start(nextStartTimeRef.current);
            nextStartTimeRef.current += audioBuffer.duration;
            audioSourcesRef.current.add(source);
          }
          
          if (message.serverContent?.interrupted) {
            for (const source of audioSourcesRef.current.values()) {
              source.stop();
            }
            audioSourcesRef.current.clear();
            nextStartTimeRef.current = 0;
          }
        },
        onerror: (e) => {
          console.error('Session error:', e);
          setStatusMessage('Connection error. Please try again.');
          setIsSessionActive(false);
          handleStopMusic();
          cleanupAudio();
        },
        onclose: (e) => {
          console.log('Session closed:', e);
          handleStopMusic();
          cleanupAudio();
          setIsSessionActive(false);
          setStatusMessage('Connection closed. Click to restart.');
        },
      };

      const connectWithRetries = async (maxRetries = 3, initialDelay = 1000) => {
        for (let attempt = 0; attempt < maxRetries; attempt++) {
          try {
            setStatusMessage(attempt > 0 ? `Connection failed, retrying... (${attempt}/${maxRetries})` : 'Connecting to companion...');
            const systemInstruction = createSystemInstruction(songForPrompt);
            const sessionPromise = startLiveSession(callbacks, systemInstruction);
            await sessionPromise;
            return sessionPromise;
          } catch (error) {
            if (error instanceof Error && error.message.includes("Requested entity was not found.")) {
                throw error; // Re-throw to be caught by the outer catch
            }
            const isRetryable = error instanceof Error && (error.message.includes('unavailable') || error.message.includes('503'));
            if (!isRetryable || attempt === maxRetries - 1) throw error;
            const delay = initialDelay * Math.pow(2, attempt);
            console.warn(`Connection attempt ${attempt + 1} failed. Retrying in ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
          }
        }
      };

      sessionPromiseRef.current = await connectWithRetries();

    } catch (error) {
      console.error('Failed to start session:', error);
      if (error instanceof Error && error.message.includes("Requested entity was not found.")) {
        onApiKeyError();
        setStatusMessage('API Key is invalid. Please select a valid key.');
      } else {
        setStatusMessage('Could not access microphone or connection failed.');
      }
      setIsSessionActive(false);
      cleanupAudio();
    }
  }, [isSessionActive, cleanupAudio, handleStopMusic, sendSilentAudioPrompt, onApiKeyError]);

  const getDisplayStatus = () => {
    if (nowPlaying) {
      return `Now Playing: "${nowPlaying.song}" by ${nowPlaying.artist}`;
    }
    if (isSessionActive) {
      if (currentInput) return 'Listening...';
      if (currentOutput) return 'Kindly is speaking...';
    }
    return statusMessage;
  };

  return React.createElement(
    "div",
    { className: "flex items-center justify-center min-h-screen font-serif bg-gradient-to-br from-[#F5F5DC] to-[#D2B48C]" },
    React.createElement(RadioInterface, {
      isActive: isSessionActive,
      statusMessage: getDisplayStatus(),
      transcripts: transcripts,
      currentInput: currentInput,
      currentOutput: currentOutput,
      onToggle: handleToggleSession
    }),
    React.createElement("audio", { ref: musicAudioRef, onEnded: handleStopMusic })
  );
};

// --- New AppContainer to handle API Key selection ---
const AppContainer = () => {
    const [isKeyReady, setIsKeyReady] = useState(false);
    const [isCheckingKey, setIsCheckingKey] = useState(true);

    const checkKey = useCallback(async () => {
        setIsCheckingKey(true);
        try {
            if (window.aistudio && typeof window.aistudio.hasSelectedApiKey === 'function') {
                const hasKey = await window.aistudio.hasSelectedApiKey();
                setIsKeyReady(hasKey);
            } else {
                // If aistudio is not available, assume key is present and let it fail later if not.
                // This allows the app to potentially run in other environments.
                setIsKeyReady(true);
            }
        } catch (e) {
            console.error("Error checking for API key:", e);
            // Default to showing the key selector on error.
            setIsKeyReady(false);
        }
        setIsCheckingKey(false);
    }, []);

    useEffect(() => {
        checkKey();
    }, [checkKey]);

    const handleSelectKey = async () => {
        try {
            if (window.aistudio && typeof window.aistudio.openSelectKey === 'function') {
                await window.aistudio.openSelectKey();
                // Assume success and update UI immediately as per guidelines
                setIsKeyReady(true);
            } else {
                alert("API key selection is not available in this environment.");
            }
        } catch (e) {
            console.error("Error opening API key selection:", e);
        }
    };
    
    const handleApiKeyError = useCallback(() => {
        setIsKeyReady(false);
    }, []);

    if (isCheckingKey) {
        return React.createElement('div', { className: 'flex items-center justify-center min-h-screen text-xl font-serif text-[#4a3728]' }, 'Initializing Radio...');
    }

    if (!isKeyReady) {
        return React.createElement(
            'div',
            { className: 'flex flex-col items-center justify-center min-h-screen font-serif bg-gradient-to-br from-[#F5F5DC] to-[#D2B48C] p-4 text-center' },
            React.createElement('div', { className: 'bg-[#c0a080] p-8 rounded-2xl shadow-2xl border-4 border-[#5b4636] max-w-lg'},
              React.createElement('h1', { className: 'text-3xl font-bold text-[#4a3728] mb-4' }, 'Welcome to Nostalgia Radio AI'),
              React.createElement('p', { className: 'text-lg text-[#5b4636] mb-6' }, 'This application requires a Google AI API key to function. Please select your API key to continue. Using this service may incur costs.'),
              React.createElement('button', {
                  onClick: handleSelectKey,
                  className: 'px-6 py-3 bg-amber-500 text-[#4a3728] font-bold rounded-lg shadow-md hover:bg-amber-600 transition-colors focus:outline-none focus:ring-2 focus:ring-amber-400 focus:ring-opacity-75'
              }, 'Select API Key'),
              React.createElement('p', { className: 'mt-4 text-sm text-[#5b4636]' },
                  'For more information on billing, please visit: ',
                  React.createElement('a', { href: 'https://ai.google.dev/gemini-api/docs/billing', target: '_blank', rel: 'noopener noreferrer', className: 'underline hover:text-amber-700' }, 'ai.google.dev/gemini-api/docs/billing')
              )
            )
        );
    }

    return React.createElement(App, { onApiKeyError: handleApiKeyError });
};


// --- Inlined index.js ---
const rootElement = document.getElementById('root');
if (!rootElement) {
  throw new Error("Could not find root element to mount to");
}
const root = ReactDOM.createRoot(rootElement);
root.render(React.createElement(React.StrictMode, null, React.createElement(AppContainer, null)));

    </script>
  </body>
</html>